# 자연어 분석을 위한 전처리

```python
# 필요 모듈
import pandas as pd
import re					# 정규표현식을 활용해 불필요한 문자열 제거
import nltk     			# 영어 형대소 분석
from konlpy.tag import Okt  # 품사별로 단어 나눠줌 
from collections import Counter		# 단어의 개수를 세어줌
import numpy as np			# 배열 구조로 만들 때 활용
```

## 데이터 가져오기

- f.read()	: 통째로 가져옴.
- f.readline() 	: 한 줄씩 가져옴
- f.readlines()	: 통째로인데 한 줄씩 리스트로 만듦.

```python
# 파일 오픈
f = open('./data/it-life-hack-6292880.txt', encoding = 'utf-8')

# 파일 내용 읽어오기
text = f.read()

# 파일 닫기
f.close

print(text)
```

> ```
> http://news.livedoor.com/article/detail/6292880/
> 2012-02-19T13 : 00 : 00 + 0900
> 구형 Mac에서 금단의 파워 업! 최신 PC 나 소프트웨어를 한꺼번에 체크 [IT 플래시백]
> 텔레비전이나 Twitter와 연계 할 수있는 PC 나 프로세서, 전환 PC 등 재미있는 PC가 속속 등장했다. 구형 Mac의 금단이라고도 할 수있는 파워 업 방법에서 NEC의 최신 PC, 화제의 ThinkPad X1 Hybrid, 새로운 보안 소프트웨어까지 한꺼번에 소개합니다.
> 
> ■ 인텔 SSD 520을 Mac에 장착! 구형 Mac은 얼마나 빨라질 것인가? (위)
> 인텔이 최신 SSD '520 시리즈'를 출시했다. 현재 SSD 중에서도 최고의 성능을 자랑하는 이 제품을 구형 Mac의 고속화를 도모한다는 점에서 리뷰 해 보았다. 조금 색다른 리뷰가되지만, 어느 정도의 효과가 있는지, 기대가 크다.
> 
> ...
> 
> [엡손 정품 잉크] 잉크 카트리지 6 색 세트 IC6CL50
> 엡손
> 출판사 : Amazon.co.jp
> 입소문을 본다
> ```

### 1. Text 정규화

```python
reg_text = re.sub('[0-9a-zA-Z:\%/\`+.",-"■ \n\s]+', '', txt)
```

>  구형 에서 금단의 파워 업! 최신 나 소프트웨어를 한꺼번에 체크 [ 플래시백] 텔레비전이나 와 연계 할 수있는 나 프로세서 전환 등 재미있는 가 속속 등장했다 구형 의 금단이라고도 할 수있는 파워 업 방법에서 의 최신 화제의 새로운 보안 소프트웨어까지 한꺼번에 소개합니다   ...  마치 축제같은 출하식! 렛츠 노트 출하 시작 월 일에 발매되는 의 출하식이 월 일 국내 제조 거점인 고베 공장에서 열렸다 동사의 컴퓨터로는 처음실시하는 출하식으로 이 제품에 얼마나 힘이 들어가 있는지 알 수있다 [엡손 정품 잉크] 잉크 카트리지 색 세트 엡손 출판사 입소문을 본다 



### 2. 형태소 생성(품사 태깅)

- okt.morphs()  : 텍스트를 형태소 단위로 나눈다.
- okt.nouns()  : 텍스트에서 명사만 뽑아낸다.
- okt.phrases()  : 텍스트에서 어절을 뽑아낸다.
- okt.pos()  : 형태소별로 품사를 태깅하여 튜플형태의 리스트를 반환`[('단어,'품사')]`

```python
okt = Okt()
token = okt.pos(text)
token
```

> ```
> [('http://news.livedoor.com/article/detail/6292880/', 'URL'),
>  ('\n', 'Foreign'),
>  ('2012-02', 'Number'),
>  ('-', 'Punctuation'),
>  ...
>   ('소문', 'Noun'),
>  ('을', 'Josa'),
>  ('본다', 'Verb'),
>  ('\n', 'Foreign')]
> ```

```python
token = okt.nouns(reg_text)
print(token)
```

> ['구형', '금단', '파워', '업', '최신', '나', ... ,출판사', '입', '소문']



### 3. 불용어 제거

stopword의 파일을 이용해 해당 파일 내에 단어가 들어있을 경우 token에서 제외시킨다.

```python
f = open("stop_words_ko.txt")
stopword = f.read()
stopword = stopword.split('\n')

# 필요하다면 아래와 같이 계속 추가하여 다시 돌린다.
stopword.extend(['계','번','뒤','업','의','해','게','용','외','트'])
```

```python
token_word = []

for token in tokens:
  if token not in stopword:
    token_word.append(token)

print(token_word)
```

> ['구형', '금단', '파워', '최신', '소프트웨어', '체크', ... ,, '출판사', '입', '소문']

2번의 token 결과와는 다름을 알 수 있다.



