# 형태소 분석

## 영어 형태소 분석

- nltk 라이브러리 사용
  -  RegexpTokenizer  :  정규식 표현에 의한 데이터 전처리 함수

```python
from nltk.tokenize import RegexpTokenizer  
from nltk import Text
import matplotlib.pyplot as plt
```

```python
text = '''
n land And now I understand What you tried to say to me How you suffered for yo
you suffered for your sanity How you tried to set them free They would not list
g hand And now I understand What you tried to say to me How you suffered for yo
you suffered for your sanity How you tried to set them free They would not list
snow And now I think I know What you tried to say to me How you suffered for yo
you suffered for your sanity How you tried to set them free They would not list
'''
```

```python
# [\w]+  : [0-9a-zA-Z_]와 같은 의미. 영문/ 숫자를 제외한 나머지 글자 제거  
regTok = RegexpTokenizer('[\w]+')
toktxt = Text(regTok.tokenize(text)) # 토큰을 이용해 text를 쪼갤 것.
```

```python
# plt.rcParams  : plt 속성 수정
plt.rcParams['figure.figsize'] = (10,5)
plt.title('NLTK Test')
toktxt.plot()
plt.show()
```

```python
# nltk가 제공하는 기능
# 문장에서 단어들의 위치값 확인 (불필요한 자료들 확인용)
toktxt.dispersion_plot(['you','How','free','list'])
```



```python
from nltk.tag import pos_tag
from nltk.tokenize import word_tokenize
```

```python
tag_lst = pos_tag()

# 내장되어져 있는 'book'이라는 문장을 불러옴
nltk.download('book',quiet=True)
```

```python
from nltk.book import *
```

```python
nltk.corpus.gutenberg.fileids() # 항목 확인
```

```python
regTok = RegexpTokenizer('[\w]+')
toktxt = Text(regTok.tokenize(guten_raw[50:985])) # 토큰을 이용해 text를 쪼갤 것.

plt.figure(figsize=(16,5))
plt.title('austen-emma Test')
toktxt.plot()
plt.show()
```

단어 단위로 전부 쪼개고, 단어의 품사를 튜플 형태로 보여줌.

```python
text = guten_raw[50:985]
tag_list = pos_tag(word_tokenize(text))
print(tag_list)
```

tag_list 에서 NN과 NNP만 뽑아보기

```python
nouns_lst = []
for tag in tag_list:
    if tag[1] == 'NN' or tag[1] == 'NNP':
        nouns_lst.append(tag[0])
```

```python
import pandas as pd

# Series 구조 이용하기
tokCount = pd.Series(nouns_lst).value_counts()
display(tokCount)
```

```python
# DataFrame 구조 이용
tok_df = pd.DataFrame(nouns_lst, columns=['단어'])
tokCount = tok_df.groupby('단어')[['단어']].count()
tokCount.columns = ['빈도수']
tokCount.sort_values('빈도수',ascending = False)
```



